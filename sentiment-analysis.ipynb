{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95d52a79-ca98-4f56-8e98-a0138213dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08be3dfb-c540-4d23-bd04-966c4c4676de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model and tokenizer\n",
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "\n",
    "# Define the class labels\n",
    "labels = ['Negative', 'Neutral', 'Positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7969b7ad-7e4b-4fa8-b437-56bee55aa62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "SINGLE TEXT ANALYSIS DEMO\n",
      "==================================================\n",
      "\n",
      "Text: Don't worry, I will come by next time!\n",
      "Negative: 0.0051\n",
      "Neutral: 0.1696\n",
      "Positive: 0.8253\n",
      "\n",
      "üîç Predicted Sentiment: **Positive**\n",
      "\n",
      "==================================================\n",
      "BATCH CSV PROCESSING\n",
      "==================================================\n",
      "‚ö†Ô∏è Created sample data at: data\\Comment.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing Sentiment: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 11.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Analysis complete! 3 records processed\n",
      "üìä Sentiment distribution:\n",
      "Predicted_Sentiment\n",
      "Positive    2\n",
      "Negative    1\n",
      "Name: count, dtype: int64\n",
      "üíæ Results saved to: C:\\Users\\emeka\\Downloads\\NLP\\results\\comments_with_sentiment.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Function to perform sentiment analysis with detailed output\n",
    "def analyze_sentiment(text):\n",
    "    # Tokenize input\n",
    "    encoded_input = tokenizer(text, return_tensors='pt', truncation=True)\n",
    "    \n",
    "    # Get model output\n",
    "    output = model(**encoded_input)\n",
    "    \n",
    "    # Convert logits to probabilities\n",
    "    scores = output.logits.detach().numpy()\n",
    "    probs = softmax(scores[0])\n",
    "    \n",
    "    # Print each class with its probability\n",
    "    print(f\"\\nText: {text}\")\n",
    "    for i, label in enumerate(labels):\n",
    "        print(f\"{label}: {probs[i]:.4f}\")\n",
    "    \n",
    "    # Return the label with the highest score\n",
    "    sentiment = labels[np.argmax(probs)]\n",
    "    print(f\"\\nüîç Predicted Sentiment: **{sentiment}**\")\n",
    "    return sentiment\n",
    "\n",
    "# Sentiment analysis function for batch processing\n",
    "def get_sentiment(text):\n",
    "    try:\n",
    "        # Handle empty text\n",
    "        if not isinstance(text, str) or len(text.strip()) == 0:\n",
    "            return \"Neutral\"\n",
    "            \n",
    "        # Preprocess input\n",
    "        encoded_input = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "        output = model(**encoded_input)\n",
    "        scores = output.logits.detach().numpy()\n",
    "        probs = softmax(scores[0])\n",
    "        return labels[np.argmax(probs)]\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing: '{text}' | {str(e)}\")\n",
    "        return \"Error\"\n",
    "\n",
    "# Bulk sentiment analysis function\n",
    "def analyze_csv_sentiment(input_csv, text_column=\"Comment\", output_csv=\"comments_with_sentiment.csv\"):\n",
    "    # Create output directory if needed\n",
    "    os.makedirs(os.path.dirname(output_csv), exist_ok=True)\n",
    "    \n",
    "    # Load CSV using OS-agnostic path\n",
    "    df = pd.read_csv(input_csv)\n",
    "    \n",
    "    # Ensure the text column exists\n",
    "    if text_column not in df.columns:\n",
    "        raise ValueError(f\"Column '{text_column}' not found. Available columns: {df.columns.tolist()}\")\n",
    "\n",
    "    # Apply sentiment analysis with progress tracking\n",
    "    tqdm.pandas(desc=\"Analyzing Sentiment\")\n",
    "    df[\"Predicted_Sentiment\"] = df[text_column].progress_apply(get_sentiment)\n",
    "\n",
    "    # Save output\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"\\n‚úÖ Analysis complete! {len(df)} records processed\")\n",
    "    print(f\"üìä Sentiment distribution:\\n{df['Predicted_Sentiment'].value_counts()}\")\n",
    "    print(f\"üíæ Results saved to: {os.path.abspath(output_csv)}\")\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example single-text analysis\n",
    "    print(\"=\"*50)\n",
    "    print(\"SINGLE TEXT ANALYSIS DEMO\")\n",
    "    print(\"=\"*50)\n",
    "    sample_text = \"Don't worry, I will come by next time!\"\n",
    "    analyze_sentiment(sample_text)\n",
    "    \n",
    "    # Batch processing example (modify paths as needed)\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"BATCH CSV PROCESSING\")\n",
    "    print(\"=\"*50)\n",
    "    input_path = os.path.join(\"data\", \"Comment.csv\")  # Relative path\n",
    "    output_path = os.path.join(\"results\", \"comments_with_sentiment.csv\")\n",
    "    \n",
    "    # Create sample data directory if missing\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    os.makedirs(\"results\", exist_ok=True)\n",
    "    \n",
    "    # Generate minimal sample CSV if none exists\n",
    "    if not os.path.exists(input_path):\n",
    "        sample_data = pd.DataFrame({\n",
    "            \"Comment\": [\n",
    "                \"This product changed my life!\",\n",
    "                \"Terrible experience, never buying again\",\n",
    "                \"It's okay, nothing special\"\n",
    "            ]\n",
    "        })\n",
    "        sample_data.to_csv(input_path, index=False)\n",
    "        print(f\"‚ö†Ô∏è Created sample data at: {input_path}\")\n",
    "    \n",
    "    # Run analysis\n",
    "    try:\n",
    "        analyze_csv_sentiment(\n",
    "            input_csv=input_path,\n",
    "            text_column=\"Comment\",\n",
    "            output_csv=output_path\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Analysis failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f485e1cc-2be3-4ae8-8b3b-c135a676e63a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
